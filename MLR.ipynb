{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9974526f-e485-4d5a-ac74-0126911125a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple Linear Regression from Scratch using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9075f4-fb79-48d3-9c4e-d65939f65181",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression (MLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e7b23-6c12-44ce-b3d4-f56cf3ba1ea9",
   "metadata": {},
   "source": [
    "Multiple Linear Regression (MLR) is a statistical technique used to model the relationship between two or more predictor variables (also called independent variables) and a single response variable (also called dependent variable). It assumes that there is a linear relationship between the predictors and the response variable, meaning that a change in one of the predictor variables will result in a proportional change in the response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc33d43-4cc8-419d-bac3-3c8e309756fd",
   "metadata": {},
   "source": [
    "MLR is an extension of simple linear regression, which involves only one predictor variable. In MLR, there can be multiple predictor variables, each with its own coefficient that indicates the strength and direction of the relationship between that predictor and the response variable, while controlling for the other predictors. The goal of MLR is to identify the combination of predictor variables that best predicts the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120f9d1-362f-4d3f-b142-122624158c5f",
   "metadata": {},
   "source": [
    "In <b>data science</b> and <b>machine learning</b>, Multiple Linear Regression (MLR) is a supervised learning algorithm used for predictive modeling. It involves building a linear equation that represents the relationship between multiple predictor variables and a response variable, and then using that equation to make predictions for new data points.\n",
    "\n",
    "MLR is a commonly used technique in machine learning because it is simple to implement and provides interpretable results. It is often used in applications such as sales forecasting, price prediction, and risk analysis.\n",
    "\n",
    "In MLR, the coefficients of the predictor variables are estimated using a technique called ordinary least squares (OLS). The OLS method finds the coefficients that minimize the sum of the squared differences between the predicted values and the actual values of the response variable. The resulting linear equation can then be used to make predictions for new data points.\n",
    "\n",
    "Like other machine learning algorithms, MLR requires careful data preparation, feature engineering, and model selection to ensure accurate and reliable predictions. It is also important to evaluate the performance of the MLR model using appropriate metrics such as mean squared error (MSE) or R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26e04f-a8f5-45ca-b908-e1035311938a",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression (MLR) Mathematical Formulas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7d3d6-ff35-4309-80d8-c86dc0fa97c6",
   "metadata": {},
   "source": [
    "#### Linear Equation for a Multilinear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbc755-3e5b-4eee-a32c-d889c6c35e9f",
   "metadata": {},
   "source": [
    "The formula for the regression equation of the <b>least-squares regression</b> line for a <b>multiple linear regression</b> with $p$ independent variables is:\n",
    "\n",
    "## $$y = b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_p x_p$$\n",
    "\n",
    "where $y$ is the dependent variable, $x_1, x_2, \\dots, x_p$ are the independent variables, $b_0$ is the y-intercept, and $b_1, b_2, \\dots, b_p$ are the coefficients of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86872c-a65c-43d3-9cee-db43b9fc958c",
   "metadata": {},
   "source": [
    "#### Regression Coefficients / Model Coefficients / Regression Slope / Slope Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b492d7-41cf-4dce-909e-83d23a30db16",
   "metadata": {},
   "source": [
    "The formula for the <b>coefficients</b> of the least-squares regression line for a multiple linear regression is:\n",
    "\n",
    "## $$\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$$\n",
    "\n",
    "where $\\mathbf{b}$ is a vector of coefficients, $\\mathbf{X}$ is the design matrix with dimensions $(n \\times p+1)$, $\\mathbf{y}$ is the vector of responses with dimensions $(n \\times 1)$, and $(\\mathbf{X}^T\\mathbf{X})^{-1}$ is the inverse of the matrix $\\mathbf{X}^T\\mathbf{X}$.\n",
    "\n",
    "<b>Note</b>: $n$ represents the number of observations or data points, and $p$ represents the number of predictor variables or features.\n",
    "The design matrix $\\mathbf{X}$ has dimensions $(n \\times p+1)$ because it includes $n$ rows, one for each observation, and $p+1$ columns, one for each predictor variable and an additional column of 1s for the intercept term.\n",
    "The response vector $\\mathbf{y}$ has dimensions $(n \\times 1)$ because it includes $n$ rows and one column, representing the response variable for each observation.\n",
    "\n",
    "or\n",
    "\n",
    "where $\\mathbf{b}$ is a $p+1$ vector of the coefficients (including the intercept), $\\mathbf{X}$ is a $n \\times (p+1)$ matrix of the independent variables (including a column of 1's for the intercept), $\\mathbf{y}$ is a $n$-dimensional vector of the dependent variable, and $(\\mathbf{X}^T \\mathbf{X})^{-1}$ is the inverse of the $p+1 \\times p+1$ matrix $\\mathbf{X}^T \\mathbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61fd986-dd61-46bf-a3a8-5506def66000",
   "metadata": {},
   "source": [
    "#### Predicted / Fitted / Estimated / Regressor / Model values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90374ff0-5df4-418b-b819-33d306e1e6f4",
   "metadata": {},
   "source": [
    "The <b>predicted</b> values can be calculated as:\n",
    "\n",
    "$$\\mathbf{\\hat{y}} = \\mathbf{X}\\mathbf{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f538c6c-6e9f-4416-ac61-8ae1542ef174",
   "metadata": {},
   "source": [
    "where $\\mathbf{\\hat{y}}$ represents the vector of predicted values of the response variable. It is a column vector of size $n \\times 1$, where $n$ is the number of observations in the dataset.\n",
    "\n",
    "$\\mathbf{X}$ represents the matrix of predictor variables. It is a matrix of size $n \\times (p+1)$, where $p$ is the number of predictor variables. Each row of the matrix represents an observation, and each column represents a predictor variable.\n",
    "\n",
    "$\\mathbf{b}$ represents the vector of regression coefficients. It is a column vector of size $(p+1) \\times 1$, where each element represents the regression coefficient for a specific predictor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951007d-8906-437c-ba8e-d818b3a78150",
   "metadata": {},
   "source": [
    "#### Residuals / Errors / Deviations / Noise / Residual Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b631a-c11c-4909-884a-f88ceab88a6d",
   "metadata": {},
   "source": [
    "The formula for the <b>residuals</b>, or <b>errors</b>, is:\n",
    "\n",
    "$$\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\mathbf{b}$$ \n",
    "<center>or</center>\n",
    "$$\\mathbf{e} = \\mathbf{y} - \\mathbf{\\hat{y}}$$\n",
    "\n",
    "where $\\mathbf{e}$ is an $n$-dimensional vector of the residuals. The residuals, which are the differences between the actual values and the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d075e4-0211-4d13-8169-a1ac3ed5e021",
   "metadata": {},
   "source": [
    "#### Intercept / Constant term / Bias term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf427b-a743-42fd-9fad-2a3898e32020",
   "metadata": {},
   "source": [
    "The intercept term, denoted by $b_0$, can be obtained as the first element of the vector $\\mathbf{b}$, which is calculated using the formula:\n",
    "\n",
    "$$\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$$\n",
    "\n",
    "where $\\mathbf{y}$ is the vector of response variables. The first element of $\\mathbf{b}$, denoted by $b_0$, is the estimated intercept term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c46efd-e166-4992-bd82-4b83302af4f6",
   "metadata": {},
   "source": [
    "#### Total Sum of Squares (TSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07529e0f-7d71-4821-8823-c96eeff4bef3",
   "metadata": {},
   "source": [
    "The formula for the <b>total sum of squares (TSS)</b> is:\n",
    "\n",
    "$$\\text{TSS} = \\sum_{i=1}^{n} (y_i - \\overline{y})^2$$\n",
    "\n",
    "where $n$ is the number of data points, $y_i$ is the $i$th value of the dependent variable, and $\\overline{y}$ is the mean of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc74891-c0c2-4e76-a3e5-8ab634b79400",
   "metadata": {},
   "source": [
    "#### Residual Sum of Squares (RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c002fd-647b-48eb-9aa5-b87d3d1969f9",
   "metadata": {},
   "source": [
    "The formula for the <b>residual sum of squares (RSS)</b> is:\n",
    "\n",
    "$$\\text{RSS} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2$$\n",
    "\n",
    "where $n$ is the number of data points, $y_i$ is the observed value of the dependent variable for the $i$th data point, and $\\hat{y_i}$ is the predicted value of the dependent variable based on the least-squares regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e4bc4-50ef-4812-9999-372f3ec449f5",
   "metadata": {},
   "source": [
    "#### R-squared / Coefficient of determination / Proportion of explained variance / Goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72834a6-2fd9-4dbf-93ca-8825ccd46fa0",
   "metadata": {},
   "source": [
    "The formula for the <b>coefficient of determination</b>, or <b>R-squared</b>, is:\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}}$$\n",
    "\n",
    "where $\\text{RSS}$ is the residual sum of squares, and $\\text{TSS}$ is the total sum of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a780bb3-bb6b-4911-99f7-48e30f51ad15",
   "metadata": {},
   "source": [
    "R-squared (also known as the coefficient of determination) measures the proportion of the variance in the target variable that is explained by the model. It takes values between 0 and 1, with higher values indicating better model performance. An R-squared of 1 indicates that the model perfectly fits the data, while an R-squared of 0 indicates that the model provides no better predictions than the mean of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998dda21-987a-47ae-a5e1-0e1c010763c0",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f092b43-cd66-4864-ace3-e8215c8b351a",
   "metadata": {},
   "source": [
    "$$ MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y_i} \\right| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd29a06-43e0-427e-a56e-ed273da93e9d",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE) is a measure of the average absolute difference between the predictions and the true values. It takes into account the magnitude of the errors, but not their direction. MAE is easy to interpret, as it gives the average magnitude of the errors in the same units as the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00cc871-339d-4961-9d25-c4ce9be72d3c",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fd947-4510-4b99-bebf-be55420251ef",
   "metadata": {},
   "source": [
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b8b21-29db-4653-8229-a2a0efeb953d",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) is similar to MAE, but it takes the square of the errors instead of their absolute value. This means that MSE gives more weight to large errors. MSE is also easy to interpret, but because it involves squaring the errors, it is more sensitive to outliers than MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0591f1b-d70b-449f-bb5c-8e231d402053",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed365b16-49bb-48f5-a94a-a9d755e2c28a",
   "metadata": {},
   "source": [
    "$$ RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975e873-5a5a-45a0-8f5d-b0737f1aefb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Root Mean Squared Error (RMSE) is simply the square root of MSE, and is often used as an alternative to MSE when we want the error metric to be in the same units as the target variable. RMSE also gives more weight to large errors, but its value is more interpretable than MSE because it is in the same units as the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8eabf-4221-4249-a8e6-a48deed3b577",
   "metadata": {},
   "source": [
    "<b>Note</b>: R-squared measures how well the model fits the data, while MAE, MSE, and RMSE measure the average difference between the predicted and actual values. MAE is less sensitive to outliers and easy to interpret, while MSE and RMSE give more weight to larger errors and are commonly used in optimization problems. RMSE is in the same units as the dependent variable and is therefore more interpretable than MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718d803-8c62-4755-ad07-9352475cd5c3",
   "metadata": {},
   "source": [
    "R-squared, MAE, MSE, and RMSE are all metrics used to evaluate the performance of regression models in machine learning. Each metric provides a different aspect of the model's performance, and choosing the most appropriate one depends on the specific problem and requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bebb2ef-0292-4dad-9d51-d7b2cc34196b",
   "metadata": {},
   "source": [
    "#### Linear Predictor Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0133e5-55db-403e-a587-fe326ff2d2ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "The equation to <b>predict</b> the value of a dependent variable $y$ using a multiple linear regression model:\n",
    "\n",
    "$$\\hat{y} = b_0 + b_1x_1 + b_2x_2 + ... + b_px_p $$\n",
    "\n",
    "where $\\hat{y}$ is the predicted value of the response variable, $b_0$ is the intercept, $b_1$, $b_2$, ..., $b_p$ are the coefficients of the predictor variables $x_1$, $x_2$, ..., $x_p$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5039e1-d15a-419c-85b4-680d6fac382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1880e7c9-49d4-49ec-9078-51d329e99a66",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression (MLR) Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bfe6f-778d-4fcc-af68-bd533c757bd5",
   "metadata": {},
   "source": [
    "$y = b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_p x_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d29d50-7ae2-45be-a1ef-a544a94c17f6",
   "metadata": {},
   "source": [
    "$$\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f255e7-6cb7-4204-a6c9-6d8873ca7e48",
   "metadata": {},
   "source": [
    "The formula is the equation for the <b>Ordinary Least Squares (OLS)</b> estimator for the regression coefficients in a multiple linear regression model.\n",
    "\n",
    "In more detail, let's break down each component of the formula:\n",
    "\n",
    "- $\\mathbf{X}$ is a matrix of predictor variables, with dimensions $n \\times (p+1)$, where $n$ is the number of observations and $p$ is the number of predictors and an additional column of 1s for the intercept term.\n",
    "\n",
    "- $\\mathbf{y}$ is a vector of response variables, with length $n$.\n",
    "\n",
    "- $\\mathbf{X}^T$ is the transpose of the matrix $\\mathbf{X}$, with dimensions $(p+1) \\times n$.\n",
    "\n",
    "- $\\mathbf{X}^T \\mathbf{X}$ is the matrix multiplication of the transpose of $\\mathbf{X}$ and $\\mathbf{X}$, with dimensions $(p+1) \\times (p+1)$.\n",
    "\n",
    "- $(\\mathbf{X}^T \\mathbf{X})^{-1}$ is the inverse of the matrix $\\mathbf{X}^T \\mathbf{X}$, if it exists. The inverse matrix is used to find the OLS estimate of the regression coefficients.\n",
    "\n",
    "- $\\mathbf{X}^T \\mathbf{y}$ is the matrix multiplication of the transpose of $\\mathbf{X}$ and $\\mathbf{y}$, with dimensions $(p+1) \\times 1$.\n",
    "\n",
    "- $\\mathbf{b}$ is a vector of length $p$ that contains the OLS estimate of the regression coefficients.\n",
    "\n",
    "The formula calculates the OLS estimate of the regression coefficients by first finding the inverse of the matrix $\\mathbf{X}^T \\mathbf{X}$, then multiplying it by the matrix $\\mathbf{X}^T \\mathbf{y}$. The resulting vector $\\mathbf{b}$ contains the OLS estimate of the regression coefficients that minimizes the sum of squared residuals between the predicted values and the actual values of the response variable $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39d1306-1ea9-40f7-8d73-eec554622955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cad9210-f9b9-4470-8eb2-51562111a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coefficients_ = None\n",
    "        self.intercept_ = None\n",
    "        self.residuals_ = None\n",
    "        self.RSS = None\n",
    "        self.TSS = None\n",
    "        self.r2score_ = None\n",
    "        self.MAE = None\n",
    "        self.MSE = None\n",
    "        self.RMSE = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n, p = X.shape[0], X.shape[1]\n",
    "        \n",
    "        # Add a column of ones to the X matrix for the intercept_ \n",
    "        ones = np.ones((n, 1))\n",
    "        X = np.hstack((ones, X))\n",
    "        \n",
    "        # Calculate the coefficients (b1, b2, ... bp) and intercept (bo)\n",
    "        X_transpose = np.transpose(X)\n",
    "        X_transpose_X = np.dot(X_transpose, X)\n",
    "        X_transpose_X_inv = np.linalg.inv(X_transpose_X)\n",
    "        X_transpose_X_inv_X_transpose = np.dot(X_transpose_X_inv, X_transpose)\n",
    "        self.coefficients_ = np.dot(X_transpose_X_inv_X_transpose, y)\n",
    "        self.intercept_ = self.coefficients_[0]\n",
    "        \n",
    "        # Calculate the predicted values and residuals\n",
    "        y_pred = np.dot(X, self.coefficients_)\n",
    "        self.residuals_ = y - y_pred\n",
    "        \n",
    "        # Calculate the residual sum of squares (RSS) anf total sum of squares (TSS) \n",
    "        self.RSS = np.sum(self.residuals_ ** 2)\n",
    "        self.TSS = np.sum((y - np.mean(y)) ** 2)   \n",
    "        \n",
    "        # Calculate the coefficient of determination (R-squared)\n",
    "        self.r2score_ = 1 - (self.RSS / self.TSS)\n",
    "        \n",
    "        # Calculate the mean absolute error (MAE)\n",
    "        self.MAE = np.mean(np.abs(self.residuals_))\n",
    "\n",
    "        # Calculate the mean squared error (MSE)\n",
    "        self.MSE = np.mean(self.residuals_ ** 2)\n",
    "\n",
    "        # Calculate the root mean squared error (RMSE)\n",
    "        self.RMSE = np.sqrt(self.MSE)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((ones, X))\n",
    "        return np.dot(X, self.coefficients_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bad377-1cbe-4c16-9cb9-39103f710532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98736f62-9931-4ae1-bdff-09c7f278aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with column names as keys and lists as values\n",
    "d = {'c1': [1, 2, 4, 3, 5], 'c2': [1, 3, 3, 2, 5], 'c3': [3, 7, 9, 5, 11]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4739313-c8a3-4c0f-9f8c-f101fae41a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c97f37d-d412-4233-9321-e882fa005085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df452b3-2a27-4355-9cea-d7d7bbb93ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3\n",
       "0   1   1   3\n",
       "1   2   3   7\n",
       "2   4   3   9\n",
       "3   3   2   5\n",
       "4   5   5  11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47873366-7901-4f31-b7b2-4d47fe09d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac01ae87-431d-4ac7-b8e7-2026ff35a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values    # inputs or features or independent variables or predictor variables\n",
    "y = df.iloc[:, -1].values     # output or target or dependent variable or response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d010fdc4-7790-4833-a19c-c9fa888b879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(5, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "1\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(X.ndim)\n",
    "print(X.shape)\n",
    "\n",
    "print(type(y))\n",
    "print(y.ndim)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1419f6d-045b-4171-92f2-be906c9b9576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 3],\n",
       "       [4, 3],\n",
       "       [3, 2],\n",
       "       [5, 5]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b341edcf-5a1c-4d9c-84df-cda5544a633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  7,  9,  5, 11], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208fe79d-8cb4-4764-9c0d-74c93697346b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce6ce6d-87ac-4fd7-960c-89e5f297fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the MultipleLinearRegression class\n",
    "model = MultipleLinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the model to the data\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e196be-6643-49e8-959e-234960a411ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilinear equation: y = 1.00 + 0.60x1 + 1.50x2\n",
      "Coefficients: [0.6 1.5]\n",
      "Intercept: 1.00\n",
      "Residuals: [-0.1  0.3  1.1 -0.8 -0.5]\n",
      "Total sum of squares (TSS): 40.00\n",
      "Residual sum of squares (RSS): 2.20\n",
      "Coefficient of determination (R^2): 0.95\n",
      "Mean Absolute Error (MAE): 0.56\n",
      "Mean Squared Error (MSE): 0.44\n",
      "Root Mean Squared Error (RMSE): 0.66\n"
     ]
    }
   ],
   "source": [
    "# Print the multiple linear equation, coefficients, and intercept\n",
    "print(f\"Multilinear equation: y = {model.coefficients_[0]:.2f} + {model.coefficients_[1]:.2f}x1 + {model.coefficients_[2]:.2f}x2\")\n",
    "print(f\"Coefficients: {model.coefficients_[1:]}\")\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "\n",
    "# Print the residuals, total sum of squares, residual sum of squares, and R-squared\n",
    "print(f\"Residuals: {model.residuals_}\")\n",
    "print(f\"Total sum of squares (TSS): {model.TSS:.2f}\")\n",
    "print(f\"Residual sum of squares (RSS): {model.RSS:.2f}\")\n",
    "print(f\"Coefficient of determination (R^2): {model.r2score_:.2f}\")\n",
    "\n",
    "# Print the (MAE), (MSE), and (RMSE)\n",
    "print(f\"Mean Absolute Error (MAE): {model.MAE:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {model.MSE:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {model.RMSE:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c0443a5-9453-436d-a1f5-94d81f23880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  7,  9,  5, 11], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74abc04c-2ab5-4850-ae39-a6392c76fff0",
   "metadata": {},
   "source": [
    "$ \\hat{y} = b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_p x_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78aba11-ea74-4d43-9c50-0965ebc7a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1,  6.7,  7.9,  5.8, 11.5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3d1aa-85b3-493f-854d-3dbc92ce6a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6038ea4-fc48-4643-8563-c908d8845d76",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ec083-2730-43a8-ba04-575a91bd4b09",
   "metadata": {},
   "source": [
    "Split the dataset into training and testing sets.\n",
    "\n",
    "Parameters:\n",
    "- X (numpy.ndarray): Array of features.\n",
    "- y (numpy.ndarray): Array of target values.\n",
    "- test_size (float): Fraction of the data to use for testing (default=0.33).\n",
    "- random_state (int): Seed for the random number generator (default=None).\n",
    "\n",
    "Returns:\n",
    "- Tuple of X_train, X_test, y_train, y_test arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f174c773-1db6-4403-99fa-43d16891975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_np(X, y, test_size=0.33, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Get the number of samples in the dataset\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Shuffle the indices of the samples\n",
    "    indices = np.random.permutation(n_samples)\n",
    "\n",
    "    # Calculate the number of samples in the training and testing sets\n",
    "    n_train_samples = int((1 - test_size) * n_samples)\n",
    "    n_test_samples = n_samples - n_train_samples\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train = X[indices[:n_train_samples]]\n",
    "    X_test = X[indices[n_train_samples:]]\n",
    "    y_train = y[indices[:n_train_samples]]\n",
    "    y_test = y[indices[n_train_samples:]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95ac937d-11db-406f-b25e-3e0844196f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "X = np.array([[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]])\n",
    "y = np.array([3, 7, 9, 5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da6b533-57b8-42fe-a5b8-b21fc74afd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 3],\n",
       "       [4, 3],\n",
       "       [3, 2],\n",
       "       [5, 5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd10263-080d-496d-8e6b-f848c19916a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  7,  9,  5, 11])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66943396-6b60-43a4-af30-cbca25d2cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_np(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbdced2d-57ad-4d8b-909f-5f66797fa60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [5, 5],\n",
       "       [4, 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ca591b0-3cfd-4b1b-aeee-424c9a5d6264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 11,  9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cfbe4fc-9aa6-49c6-99c7-124c0a2c6744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [3, 2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2646d44a-3328-413e-ab3e-75f02a21914c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a0879-302a-4247-8da0-355f67850c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b493bc18-f7c5-46c7-953e-011b3837fb75",
   "metadata": {},
   "source": [
    "## Python + NumPy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e8ac16e-d53e-4e9f-a2d9-bcb055b2af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6f5eca3-c2c8-46ab-b5c1-16b128eb9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to the X matrix for the intercept_ \n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((ones, X))\n",
    "        \n",
    "        # Calculate the coefficients (b1, b2, ... bp) and intercept (bo)\n",
    "        X_transpose = np.transpose(X)\n",
    "        X_transpose_X = np.dot(X_transpose, X)\n",
    "        X_transpose_X_inv = np.linalg.inv(X_transpose_X)\n",
    "        X_transpose_X_inv_X_transpose = np.dot(X_transpose_X_inv, X_transpose)\n",
    "        self.coef_ = np.dot(X_transpose_X_inv_X_transpose, y)\n",
    "        self.intercept_ = self.coef_[0]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((ones, X))\n",
    "        return np.dot(X, self.coef_)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((ones, X))\n",
    "        y_pred = np.dot(X, self.coef_)\n",
    "        residuals = y - y_pred\n",
    "        RSS = np.sum(residuals ** 2)\n",
    "        TSS = np.sum((y - np.mean(y)) ** 2)\n",
    "        r2score = 1 - (RSS / TSS)\n",
    "        return r2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce167836-4d95-4c38-9d63-95d2338c2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.33, random_state=None):\n",
    "    # Set random seed if specified\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle data and split into training and testing sets\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    split_index = int(X.shape[0] * (1 - test_size))\n",
    "    X_train, X_test = X[indices[:split_index]], X[indices[split_index:]]\n",
    "    y_train, y_test = y[indices[:split_index]], y[indices[split_index:]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb6a8ced-aba9-4e99-8406-18a3dbb08f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def r2_score(y_true, y_pred):\n",
    "        SST = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "        RSS = np.sum((y_true - y_pred) ** 2)\n",
    "        return 1 - (RSS / SST)\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_absolute_error(y_true, y_pred):\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_squared_error(y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        mse = np.mean((y_true - y_pred) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4b732-1d00-41e5-9af6-14bf2428d460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44803c1f-c2d4-4837-b4b4-afc566540202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "p = 3\n",
    "X = np.random.randn(n, p)\n",
    "y = 2*X[:,0] + 3*X[:,1] - 1*X[:,2] + np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa401f-4aff-4429-9dcc-6d7f73b49eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32a83978-e8f4-4a16-b50c-d8cde636e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a5cfdda-de36-4a37-9fdd-eb69889e34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.DataFrame(X, columns=['X1', 'X2', 'X3']), pd.DataFrame(y, columns=['y'])], axis=1, )\n",
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37bb1bff-86a9-4406-800d-49b8e2bf077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>-0.898048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-0.234137</td>\n",
       "      <td>2.017556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579213</td>\n",
       "      <td>0.767435</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>6.677498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.542560</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>0.770967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-3.551900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3         y\n",
       "0  0.496714 -0.138264  0.647689 -0.898048\n",
       "1  1.523030 -0.234153 -0.234137  2.017556\n",
       "2  1.579213  0.767435 -0.469474  6.677498\n",
       "3  0.542560 -0.463418 -0.465730  0.770967\n",
       "4  0.241962 -1.913280 -1.724918 -3.551900"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880345aa-bdc7-495a-bf56-7a5e92aa7e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56bfd68b-d27f-4195-b435-e0f907775464",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4dc9f78-b7ad-4022-87b2-29b52f8dcfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultipleLinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c228050f-04c2-4c80-9148-cee335dae6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (R^2): 0.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coefficient of determination (R^2): {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "261a1f91-e475-45e1-8276-86ecb44dcc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (R^2): 0.92\n",
      "Mean Absolute Error (MAE): 0.83\n",
      "Mean Squared Error (MSE): 1.08\n",
      "Root Mean Squared Error (RMSE): 1.04\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coefficient of determination (R^2): {Metrics.r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {Metrics.mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {Metrics.mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {Metrics.root_mean_squared_error(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53e91d22-a67d-4376-95ee-9748c9278ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear equation: y = 0.0120 + 1.9183x1 + 3.0357x2 + -1.1099x3\n",
      "Slope: [ 1.91831705  3.03573198 -1.10988093]\n",
      "Intercept: 0.0120\n"
     ]
    }
   ],
   "source": [
    "print(f\"Multiple linear equation: y = {model.intercept_:.4f} + {model.coef_[1]:.4f}x1 + {model.coef_[2]:.4f}x2 + {model.coef_[3]:.4f}x3\")\n",
    "print(f\"Slope: {model.coef_[1:]}\")\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071add1b-5201-43f6-8067-b8d856274df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e48585-4823-4236-b77f-f421066710db",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21f64671-254c-4b4e-bab8-bb85faa35f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7cc513c-0ed1-4a66-9620-6ac134383456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee09ff25-d1d2-47e4-b000-75dfcad6229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b66c5488-f2ef-4c1c-b49c-1f6d9839d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec95363b-c14a-4786-8594-0efa828ff4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f56f27e-db76-4de8-9516-aa28ed409732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (R^2): 0.94\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coefficient of determination (R^2): {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16f878fc-c9cd-452f-b957-9f2a124f8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (R^2): 0.94\n",
      "Mean Absolute Error (MAE): 0.72\n",
      "Mean Squared Error (MSE): 0.76\n",
      "Root Mean Squared Error (RMSE): 0.87\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coefficient of determination (R^2): {r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "040daeeb-b166-44b2-a439-9f857be63f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilinear equation: y = 0.2014 + 2.0314x1 + 2.9009x2 + -1.0094x3\n",
      "Slope: [ 2.0314386   2.90090856 -1.00939987]\n",
      "Intercept: 0.2014\n"
     ]
    }
   ],
   "source": [
    "print(f\"Multilinear equation: y = {model.intercept_:.4f} + {model.coef_[0]:.4f}x1 + {model.coef_[1]:.4f}x2 + {model.coef_[2]:.4f}x3\")\n",
    "print(f\"Slope: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69f24d-ed6c-4585-94f5-2a76dd5f95cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0de3a371-2a60-4c66-99a5-0c58009aecf5",
   "metadata": {},
   "source": [
    "## Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f1ed8e7-7511-442a-bc47-ee03f634eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40c7fa79-f3fe-4861-9d19-2dc61bd8b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f575f69a-3bf7-4358-a821-0cbded9aa33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79209e8c-6edd-4ad6-843c-2fdb0156e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5842c69e-7b5b-44a0-8d73-9062f9b57ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b41c492-970e-4b5c-82ee-f78f2a044131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, X_train).fit()\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18099bed-a534-430a-a7c1-e586f0bb17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9445253068209857\n"
     ]
    }
   ],
   "source": [
    "print(\"R-squared:\", model.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30f2ee20-4659-417e-ad43-04c403dcdddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (R^2): 0.94\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coefficient of determination (R^2): {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cd3e588-0760-41e0-9159-6eb68e72a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   357.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 25 Feb 2023</td> <th>  Prob (F-statistic):</th> <td>1.71e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:48:27</td>     <th>  Log-Likelihood:    </th> <td> -87.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    67</td>      <th>  AIC:               </th> <td>   183.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    63</td>      <th>  BIC:               </th> <td>   192.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2014</td> <td>    0.118</td> <td>    1.707</td> <td> 0.093</td> <td>   -0.034</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.0314</td> <td>    0.137</td> <td>   14.813</td> <td> 0.000</td> <td>    1.757</td> <td>    2.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    2.9009</td> <td>    0.131</td> <td>   22.219</td> <td> 0.000</td> <td>    2.640</td> <td>    3.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -1.0094</td> <td>    0.111</td> <td>   -9.086</td> <td> 0.000</td> <td>   -1.231</td> <td>   -0.787</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.036</td> <th>  Durbin-Watson:     </th> <td>   1.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.982</td> <th>  Jarque-Bera (JB):  </th> <td>   0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.040</td> <th>  Prob(JB):          </th> <td>   0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.869</td> <th>  Cond. No.          </th> <td>    1.54</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.945\n",
       "Model:                            OLS   Adj. R-squared:                  0.942\n",
       "Method:                 Least Squares   F-statistic:                     357.6\n",
       "Date:                Sat, 25 Feb 2023   Prob (F-statistic):           1.71e-39\n",
       "Time:                        12:48:27   Log-Likelihood:                -87.947\n",
       "No. Observations:                  67   AIC:                             183.9\n",
       "Df Residuals:                      63   BIC:                             192.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2014      0.118      1.707      0.093      -0.034       0.437\n",
       "x1             2.0314      0.137     14.813      0.000       1.757       2.305\n",
       "x2             2.9009      0.131     22.219      0.000       2.640       3.162\n",
       "x3            -1.0094      0.111     -9.086      0.000      -1.231      -0.787\n",
       "==============================================================================\n",
       "Omnibus:                        0.036   Durbin-Watson:                   1.811\n",
       "Prob(Omnibus):                  0.982   Jarque-Bera (JB):                0.066\n",
       "Skew:                           0.040   Prob(JB):                        0.967\n",
       "Kurtosis:                       2.869   Cond. No.                         1.54\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91365586-7849-4b39-98d5-b468d0b4deb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "787649bd-c3d6-4398-b73f-869ce6a85c1a",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50ffd53e-3889-49b4-abf9-99474f0b8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12b86d56-fea1-4763-b967-559cf552f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X for the intercept\n",
    "        X = np.c_[np.ones(X.shape[0]), X]   \n",
    "        \n",
    "        # Compute coefficients and set intercept to first coefficient\n",
    "        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y  \n",
    "        self.intercept_ = self.coef_[0]  \n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X for the intercept\n",
    "        X = np.c_[np.ones(X.shape[0]), X]  \n",
    "        return X @ self.coef_\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        RSS = np.sum((y - y_pred) ** 2)\n",
    "        TSS = np.sum((y - np.mean(y)) ** 2)\n",
    "        r2score = 1 - (RSS / TSS)\n",
    "        return r2score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc80340-c517-4364-a32a-0f9c3dae78d0",
   "metadata": {},
   "source": [
    "## PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a052dc7c-37b7-455c-ad3b-5c64c9a6b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b49d1db4-a68a-43e3-809f-fc2a31bcf827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X for the intercept\n",
    "        ones = torch.ones((X.shape[0], 1), dtype=torch.float32)\n",
    "        X = torch.cat((ones, X), dim=1)\n",
    "        \n",
    "        # Compute coefficients and set intercept to first coefficient\n",
    "        X_t = torch.transpose(X, 0, 1)\n",
    "        self.coef_ = torch.inverse(X_t @ X) @ X_t @ y\n",
    "        self.intercept_ = self.coef_[0]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X for the intercept\n",
    "        ones = torch.ones((X.shape[0], 1), dtype=torch.float32)\n",
    "        X = torch.cat((ones, X), dim=1)\n",
    "        return X @ self.coef_\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        RSS = torch.sum((y - y_pred) ** 2)\n",
    "        TSS = torch.sum((y - torch.mean(y)) ** 2)\n",
    "        r2score = 1 - (RSS / TSS)\n",
    "        return r2score.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b10387-d693-468c-9ea4-64a3780dbd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf151878-a22c-468c-956c-a9751eff64ca",
   "metadata": {},
   "source": [
    "## Data Transformations  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b3967-92d6-42f2-9557-d93670ac3458",
   "metadata": {},
   "source": [
    "<b>Preprocessing for Machine Learning (Prepping Data for Modelling)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf5796-b4b5-4122-bda6-f7c2c3cc742e",
   "metadata": {},
   "source": [
    "Transforming Numeric Data (Feature Scaling)\n",
    "- Linear Scaling / Min-Max Normalization / Normalization\n",
    "- Z-score / Standard Score / Z-score Normalization / Standardization\n",
    "\n",
    "Transforming Categorical Data \n",
    "- Label Encoding \n",
    "- OneHot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d78c4066-9dd5-49e6-ad3e-97457e283892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbb836f2-a263-4d12-bb4e-faa0e7c45e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.std_\n",
    "    \n",
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.min_ = None\n",
    "        self.max_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.min_ = np.min(X, axis=0)\n",
    "        self.max_ = np.max(X, axis=0)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return (X - self.min_) / (self.max_ - self.min_)\n",
    "    \n",
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.categories_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.categories_ = np.unique(X)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.categories_ is None:\n",
    "            raise ValueError(\"Call fit method first\")\n",
    "        \n",
    "        X_encoded = np.zeros(len(X), dtype=int)\n",
    "        for i, category in enumerate(self.categories_):\n",
    "            X_encoded[X == category] = i\n",
    "            \n",
    "        return X_encoded\n",
    "    \n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        self.categories_ = None\n",
    "        self.num_categories_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.categories_ = np.unique(X)\n",
    "        self.num_categories_ = len(self.categories_)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.num_categories_ is None:\n",
    "            raise ValueError(\"Call fit method first\")\n",
    "        \n",
    "        X_encoded = np.zeros((len(X), self.num_categories_))\n",
    "        for i, category in enumerate(self.categories_):\n",
    "            X_encoded[:, i] = (X == category)\n",
    "            \n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f29d9-9c5a-4536-a722-414e68389427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff1708ec-3c7e-4131-b78d-c76552854462",
   "metadata": {},
   "source": [
    "## Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a37cf6-46e9-4066-bfaf-d2e12f3363b2",
   "metadata": {},
   "source": [
    "<b>Linear Regression</b> (SLR or MLR or PLR) is a popular technique for modeling the relationship between a dependent variable and one or more independent variables. There are several methods to implement linear regression.\n",
    "\n",
    "- <b>Ordinary Least Squares (OLS)</b>: OLS is a classic method that minimizes the sum of squared residuals between the observed and predicted values of the dependent variable. OLS assumes that the residuals are normally distributed and have constant variance.\n",
    "\n",
    "$$y = b_0 + b_1 x$$\n",
    "\n",
    "$$y = b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n$$\n",
    "\n",
    "$$y = b_0 + b_1 x + b_2 x^2 + b_3 x^3 + \\cdots + b_n x^n$$\n",
    "\n",
    "- <b>Ridge Regression</b>: Ridge regression is a variant of linear regression that includes a penalty term for large parameter values. The penalty term is controlled by a hyperparameter, which is chosen using cross-validation. Ridge regression can help to reduce overfitting in the model.\n",
    "\n",
    "$$y = b_0 + b_1x_1 + b_2x_2 + ... + b_nx_n + \\lambda(b_1^2 + b_2^2 + ... + b_n^2)$$\n",
    "\n",
    "$$y = b_0 + b_1x_1 + b_2x_2 + ... + b_nx_n + \\lambda\\sum_{i=1}^{n}b_i^2$$\n",
    "\n",
    "$$y = b_0 + \\sum_{i=1}^{n} b_i x_i + \\lambda \\sum_{i=1}^{n} b_i^2$$\n",
    "\n",
    "- <b>Lasso Regression</b>: Lasso regression is another variant of linear regression that includes a penalty term, but uses the absolute value of the parameter values instead of the squared values. Lasso regression can be used for feature selection, as it tends to set the coefficients of irrelevant features to zero.\n",
    "\n",
    "$$y = b_0 + \\sum_{i=1}^{n} b_i x_i + \\lambda \\sum_{i=1}^{n} |b_i|$$\n",
    "\n",
    "- <b>Elastic Net Regression</b>: Elastic net regression is a combination of ridge and lasso regression, which includes both L1 and L2 penalty terms. Elastic net regression can be used to balance the bias-variance tradeoff and can be particularly useful when there are many correlated features.\n",
    "\n",
    "$$y = b_0 + \\sum_{i=1}^{n} b_i x_i + \\lambda_1 \\sum_{i=1}^{n} |b_i| + \\lambda_2 \\sum_{i=1}^{n} b_i^2$$\n",
    "\n",
    "- <b>Bayesian Linear Regression</b>: Bayesian linear regression is a method that uses Bayesian statistics to estimate the parameters of the regression model. It involves specifying prior distributions over the parameters and using Bayes' theorem to update the priors based on the observed data.\n",
    "\n",
    "- <b>Gradient Descent</b>: Gradient descent is an iterative optimization algorithm that minimizes the cost function (the sum of squared residuals) by updating the model parameters in the direction of the negative gradient of the cost function.\n",
    "    - Batch Gradient Descent (BGD)\n",
    "    - Stochastic Gradient Descent (SGD)\n",
    "    - Mini-Batch Gradient Descent (MBGD)\n",
    "    - Momentum-based Gradient Descent\n",
    "    - Adagrad\n",
    "    - Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5caccc-9735-4cd0-8a18-9ee4062e265c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd37724e-6539-4b43-8820-8fcd7ebc0ea2",
   "metadata": {},
   "source": [
    "@rizwan-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab5e24-afa4-4e17-beed-30eb53798f07",
   "metadata": {},
   "source": [
    "## Happy Learning :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
